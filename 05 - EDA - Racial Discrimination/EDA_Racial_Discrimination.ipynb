{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of callbacks for black-sounding names\n",
    "sum(data[data.race=='w'].call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ad</th>\n",
       "      <th>education</th>\n",
       "      <th>ofjobs</th>\n",
       "      <th>yearsexp</th>\n",
       "      <th>honors</th>\n",
       "      <th>volunteer</th>\n",
       "      <th>military</th>\n",
       "      <th>empholes</th>\n",
       "      <th>occupspecific</th>\n",
       "      <th>...</th>\n",
       "      <th>compreq</th>\n",
       "      <th>orgreq</th>\n",
       "      <th>manuf</th>\n",
       "      <th>transcom</th>\n",
       "      <th>bankreal</th>\n",
       "      <th>trade</th>\n",
       "      <th>busservice</th>\n",
       "      <th>othservice</th>\n",
       "      <th>missind</th>\n",
       "      <th>ownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nonprofit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  id ad  education  ofjobs  yearsexp  honors  volunteer  military  empholes  \\\n",
       "0  b  1          4       2         6       0          0         0         1   \n",
       "1  b  1          3       3         6       0          1         1         0   \n",
       "2  b  1          4       1         6       0          0         0         0   \n",
       "3  b  1          3       4         6       0          1         0         1   \n",
       "4  b  1          3       3        22       0          0         0         0   \n",
       "\n",
       "   occupspecific    ...      compreq  orgreq  manuf  transcom  bankreal trade  \\\n",
       "0             17    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "1            316    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "2             19    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "3            313    ...          1.0     0.0    1.0       0.0       0.0   0.0   \n",
       "4            313    ...          1.0     1.0    0.0       0.0       0.0   0.0   \n",
       "\n",
       "  busservice othservice  missind  ownership  \n",
       "0        0.0        0.0      0.0             \n",
       "1        0.0        0.0      0.0             \n",
       "2        0.0        0.0      0.0             \n",
       "3        0.0        0.0      0.0             \n",
       "4        0.0        1.0      0.0  Nonprofit  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. What test is appropriate for this problem? Does CLT apply? ###\n",
    "The problem statement is about two groups and their proportion of success vs. failures. It is therefore appropriate to use significance testing given the *difference* of two proportions.\n",
    "\n",
    "And yes, central limit theorem would apply. As long as we have a discrete distribution, even if its shape does not resemble a normal curve at all, when we take samples of the distribution and when we average the samples and plot them, we'll arrive at a normal curve no matter what.\n",
    "\n",
    "### 2. What are the null and alternate hypotheses? ###\n",
    "* **Null Hypothesis**: $Proportion_{white\\space callback} = Proportion_{black\\space callback}$\n",
    "* **Alternative Hypothesis**: $Proportion_{white\\space callback} \\neq Proportion_{black\\space callback}$\n",
    "\n",
    "We can interpret the null hypothesis as the difference between the two *success* proportions is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign our critical value `alpha` as 0.05 so if our p-value is less than this, we'd reject the null hypothesis. The length of the sampled dataframes and the probability of success for both groups are specified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical value: 0.05\n",
      "Proportion of white group getting callback: 9.65%\n",
      "Proportion of black group getting callback: 6.45%\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "w_size = len(w)\n",
    "b_size = len(b)\n",
    "\n",
    "w_success = len(w[w[\"call\"] == 1]) / w_size\n",
    "b_success = len(b[b[\"call\"] == 1]) / b_size\n",
    "\n",
    "print(\"Critical value: %.2f\" % alpha)\n",
    "print(\"Proportion of white group getting callback: %.2f%%\" \\\n",
    "      % (w_success*100))\n",
    "print(\"Proportion of black group getting callback: %.2f%%\" \\\n",
    "      % (b_success*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take the frequentist approach. We first calculate the pooled sample proportion `pooled_prop`. From there, the standard error `SE` can be derived by mutliplying the probability of sucess with the probability of failure and dividing it by the standard deviation of the sample population. Finally we get the *z-statistic* by simply getting the difference of the success proportions of both groups and dividing them by the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled sample proportion: 0.080%\n",
      "Standard Error: 0.008%\n",
      "Z-statistic: 4.108%\n"
     ]
    }
   ],
   "source": [
    "pooled_prop = (w_success*w_size + b_success*b_size) \\\n",
    "                / (w_size + b_size)\n",
    "\n",
    "SE = (pooled_prop * (1-pooled_prop) \\\n",
    "     * ((1/w_size) + (1/b_size)))**0.5\n",
    "\n",
    "z = (w_success - b_success) / SE\n",
    "\n",
    "print(\"Pooled sample proportion: %.3f%%\" % pooled_prop)\n",
    "print(\"Standard Error: %.3f%%\" % SE)\n",
    "print(\"Z-statistic: %.3f%%\" % z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the above elements just by using formulas but in order for us to get a precise p-value we'll use scipy stats instead of a z-table.\n",
    "\n",
    "We see that the p-value turns out to be much less than our critical value. And so we cannot accept the null hypothesis. This means that unfortunately, there *is* a significant difference between the successes of white applicants and of black applicants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.00002\n",
      "\n",
      "P-Value larger than alpha? False\n",
      "Proportion of the two groups ARE different\n"
     ]
    }
   ],
   "source": [
    "p = stats.norm.sf(abs(z))\n",
    "\n",
    "print(\"P-value: %.5f\\n\" % p)\n",
    "print(\"P-Value larger than alpha? %s\" % str(p > alpha))\n",
    "if p > alpha:\n",
    "    print(\"Proportion of the two groups are NOT different\")\n",
    "else:\n",
    "    print(\"Proportion of the two groups ARE different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a step forward and see how much difference the two groups have. From the simple calculation below, we arrive at `3.2%` as our `prop_diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion difference between two groups: 3.2%\n"
     ]
    }
   ],
   "source": [
    "prop_diff = w_success - b_success\n",
    "\n",
    "print(\"Proportion difference between two groups: %.1f%%\" \\\n",
    "      % (prop_diff*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is just from *one* trial. Who's to say that what we've gotten is actually on the fringe of the norm? And so we proceed to getting our confidence interval so we have a feel of where the true proportional difference lies.\n",
    "\n",
    "We'll use `95%` as our confidence level, so as we extend outward from the distribution mean, we get two borders that contain 95% of the curve area. The `distance` below is the cumulative distribution proportion up to that *right* border. We multiply this by the standard deviation of the difference between the proportions. This is the `std_dev_diff` below.\n",
    "\n",
    "Our confidence interval then is `0.032` plus or minus `0.0153`.\n",
    "\n",
    "This then tells us that if we've repeated the experiment several times, we'd see in 95% of them that the *true* proportion difference of the two groups is between `1.68%` and `4.73%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: 0.015\n",
      "\n",
      "True proportion difference is between 1.68% and 4.73%.\n"
     ]
    }
   ],
   "source": [
    "conf_lev = 0.95\n",
    "\n",
    "distance = stats.norm.ppf((1+conf_lev)/2)\n",
    "std_dev_diff = ((w_success *(1-w_success))/w_size \\\n",
    "                + (b_success *(1-b_success))/b_size)**0.5\n",
    "conf_int = distance * std_dev_diff\n",
    "\n",
    "print(\"Confidence Interval: %.3f\\n\" % conf_int)\n",
    "print(\"True proportion difference is between %.2f%% and %.2f%%.\" \\\n",
    "      % ((prop_diff - conf_int)*100, (prop_diff + conf_int)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can reproduce the same conclusion by taking the bootstrap approach. Again `prop_diff` is the difference between the proportion of successes of both groups. In order for us to test our hypothesis, we'll assume truth in the null hypothesis by performing permutation on the original `data` dataframe 10,000 times. We'll actually shuffle the index of the dataframe then classify the first half as the `w` group and the next as the `b` group. From there, we take the mean of each permutated group. The difference of the mean per loop is then added onto the `simulation` array.\n",
    "\n",
    "The p-value `p` is just the proportion of the instances that each `simulation` element happens to be greater than or equal to the `prop_diff`. This didn't happen at all in the 10,000 trials so our p-value is `0`. It is therefore incredibly rare to see such difference between successful callbacks from white-sounding names and those from black-sounding names **if** it were purely up to chance. Clearly, there is a factor of bias then.\n",
    "\n",
    "This is the exact same conclusion we got from the frequentist approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.00000\n",
      "\n",
      "P-Value larger than alpha? False\n",
      "Proportion of the two groups ARE different\n"
     ]
    }
   ],
   "source": [
    "prop_diff = w_success - b_success\n",
    "\n",
    "np.random.seed(42)\n",
    "simulation = []\n",
    "for i in range(10000):\n",
    "    rand_ind = np.random.randint(0, len(data), len(data))\n",
    "    perm_data = data[\"call\"].iloc[rand_ind]\n",
    "    perm_w = perm_data[:len(w)]\n",
    "    perm_b = perm_data[len(b):]\n",
    "    perm_w_mean = np.mean(perm_w)\n",
    "    perm_b_mean = np.mean(perm_b)\n",
    "    simulation.append(perm_w_mean - perm_b_mean)\n",
    "simulation = np.array(simulation)\n",
    "\n",
    "p = np.sum(simulation >= prop_diff)/10000\n",
    "print(\"P-value: %.5f\\n\" % p)\n",
    "print(\"P-Value larger than alpha? %s\" % str(p > alpha))\n",
    "if p > alpha:\n",
    "    print(\"Proportion of the two groups are NOT different\")\n",
    "else:\n",
    "    print(\"Proportion of the two groups ARE different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what *could* be the actual value for the difference between the two proportions using confidence intervals. To get the 95% confidence bounds, we simply take the 2.5th and 97.5th percentile of our `simulation` distribution. The area between these borders are 95%.\n",
    "\n",
    "Like with what we've seen in the previous approach, we're 95% confident that the *true* proportion difference of the two groups is between `1.64%` and `4.72%`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: 0.015\n",
      "\n",
      "True proportion difference is between 1.64% and 4.72%.\n"
     ]
    }
   ],
   "source": [
    "conf_int = np.percentile(simulation, [2.5, 97.5])\n",
    "\n",
    "print(\"Confidence Interval: %.3f\\n\" % conf_int[1])\n",
    "print(\"True proportion difference is between %.2f%% and %.2f%%.\" \\\n",
    "      % ((prop_diff + conf_int[0])*100, (prop_diff + conf_int[1])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a story describing the statistical significance in the context or the original problem. ###\n",
    "The proportion of applicants with white-sounding names that get callbacks is 9.65%. For applicants with black-sounding names, the rate is 6.45%. That's a mean difference of 3.2%, which, from what we've calculated, *is* significant. In a simulation of 10,000 trials, not one had that much disparity when we've assumed no difference between the groups. So the numbers tell us that there is evidence of discrimination in the hiring process (from unconscious bias, perhaps), that not even a random process can justify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis? \n",
    "One might say that perhaps race did not play much of a factor in the experiment given that more weight is naturally given to education, experience, etc. But as I re-read the problem statement, it was indicated that names were *randomly* assigned to the resumes. Below, I made a quick check to see how much difference there are between those given with white names and those given with black names *in terms of* honors, education, and experience. As the report mentioned, it appears to be random indeed. So the only factor that's differentiating the two groups is race alone. So, yes, this only further approves our statistical finding that there *is* discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in `honors`: 0.29%\n",
      "Difference in `education`: 0.49%\n",
      "Difference in `experience`: 2.67%\n"
     ]
    }
   ],
   "source": [
    "honors = np.mean(w[\"honors\"]) - np.mean(b[\"honors\"])\n",
    "education = np.mean(w[\"education\"]) - np.mean(b[\"education\"])\n",
    "experience = np.mean(w[\"yearsexp\"]) - np.mean(b[\"yearsexp\"])\n",
    "\n",
    "print(\"Difference in `honors`: %.2f%%\" \\\n",
    "      % (honors*100))\n",
    "print(\"Difference in `education`: %.2f%%\" \\\n",
    "      % (education*100))\n",
    "print(\"Difference in `experience`: %.2f%%\" \\\n",
    "      % (experience*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
